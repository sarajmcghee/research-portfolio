{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bea0e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import joblib\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d817108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio classes example: ['aguimp', 'alpina', 'aluco', 'apiaster', 'apivorus']\n",
      "Num audio features: 169\n"
     ]
    }
   ],
   "source": [
    "audio_model = joblib.load(\"audio_model.joblib\")\n",
    "audio_scaler = joblib.load(\"audio_scaler.joblib\")\n",
    "audio_feature_columns = joblib.load(\"audio_feature_columns.joblib\")\n",
    "audio_classes = joblib.load(\"audio_classes.joblib\")\n",
    "\n",
    "print(\"Audio classes example:\", audio_classes[:5])\n",
    "print(\"Num audio features:\", len(audio_feature_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62b08e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classes example: ['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet']\n",
      "Num image classes: 200\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(\"image_model.pth\", map_location=device)\n",
    "image_classes = ckpt[\"classes\"]\n",
    "\n",
    "image_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "image_model.fc = nn.Linear(image_model.fc.in_features, len(image_classes))\n",
    "image_model.load_state_dict(ckpt[\"model_state\"])\n",
    "image_model = image_model.to(device)\n",
    "image_model.eval()\n",
    "\n",
    "print(\"Image classes example:\", image_classes[:5])\n",
    "print(\"Num image classes:\", len(image_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49532288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_from_probs(probs, labels, k=5):\n",
    "    idx = np.argsort(probs)[::-1][:k]\n",
    "    return [(labels[i], float(probs[i])) for i in idx]\n",
    "\n",
    "def pretty_image_label(label):\n",
    "    # \"001.Black_footed_Albatross\" -> \"Black footed Albatross\"\n",
    "    if \".\" in label:\n",
    "        label = label.split(\".\", 1)[1]\n",
    "    return label.replace(\"_\", \" \")\n",
    "\n",
    "# Image transforms (ImageNet normalization for ResNet)\n",
    "img_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def predict_image_topk(img_path, k=5):\n",
    "    x = img_tfms(Image.open(img_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        probs = F.softmax(image_model(x), dim=1).squeeze(0).cpu().numpy()\n",
    "    return probs, topk_from_probs(probs, image_classes, k=k)\n",
    "\n",
    "def predict_audio_topk(X_audio_row_df, k=5):\n",
    "    # Ensure correct column order\n",
    "    X_audio_row_df = X_audio_row_df[audio_feature_columns]\n",
    "    probs = audio_model.predict_proba(audio_scaler.transform(X_audio_row_df)).squeeze(0)\n",
    "    return probs, topk_from_probs(probs, audio_classes, k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0813e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional mapping: audio label -> keyword or canonical common name\n",
    "AUDIO_TO_CANON = {\n",
    "    \"trochilus\": \"hummingbird\",\n",
    "    \"argentatus\": \"gull\",\n",
    "    \"arvensis\": \"lark\",\n",
    "}\n",
    "\n",
    "def agreement_check(image_topk_labels, audio_top1_label):\n",
    "    aud = AUDIO_TO_CANON.get(audio_top1_label, None)\n",
    "    if aud is None:\n",
    "        return (\"no_mapping\", f\"No mapping for audio label '{audio_top1_label}' yet.\")\n",
    "\n",
    "    aud = aud.lower()\n",
    "    img_topk_pretty = [pretty_image_label(l).lower() for l, _ in image_topk_labels]\n",
    "\n",
    "    if aud in img_topk_pretty[0]:\n",
    "        return (\"strong\", f\"‚úÖ Strong agreement: '{aud.title()}' matches IMAGE top-1\")\n",
    "    if any(aud in lab for lab in img_topk_pretty[:5]):\n",
    "        return (\"weak\", f\"üü° Weak agreement: '{aud.title()}' appears in IMAGE top-5\")\n",
    "    return (\"none\", f\"‚ùå No agreement: '{aud.title()}' not found in IMAGE top-5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0873d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimodal_assistant(img_path, X_audio_row_df, k=5):\n",
    "    _, img_topk = predict_image_topk(img_path, k=k)\n",
    "    _, aud_topk = predict_audio_topk(X_audio_row_df, k=k)\n",
    "\n",
    "    print(\"=== Multimodal Bird ID (learning mode) ===\\n\")\n",
    "\n",
    "    print(\"IMAGE top predictions:\")\n",
    "    for lab, p in img_topk:\n",
    "        print(f\"  ‚Ä¢ {pretty_image_label(lab):35s}  {p:.3f}\")\n",
    "\n",
    "    print(\"\\nAUDIO top predictions:\")\n",
    "    for lab, p in aud_topk:\n",
    "        print(f\"  ‚Ä¢ {lab:35s}  {p:.3f}\")\n",
    "\n",
    "    print(\"\\nAgreement check:\")\n",
    "    status, msg = agreement_check(img_topk, aud_topk[0][0])\n",
    "    print(\" \", msg)\n",
    "    print(\"\\nRecommendation:\")\n",
    "    if status == \"strong\":\n",
    "      print(f\"  ‚úÖ Recommend: {pretty_image_label(img_topk[0][0])} (strong multimodal agreement)\")\n",
    "    elif status == \"weak\":\n",
    "      print(f\"  üü° Leaning: {pretty_image_label(img_topk[0][0])} (audio agrees in top-5)\")\n",
    "    else:\n",
    "      print(\"  ‚ö†Ô∏è No agreement ‚Äî consider another photo or audio clip, or trust the stronger model confidence.\")\n",
    "\n",
    "    return {\"image_topk\": img_topk, \"audio_topk\": aud_topk, \"agreement\": status}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08eba430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using image: /Users/saramcghee/.cache/kagglehub/datasets/veeralakrishna/200-bird-species-with-11788-images/versions/1/CUB_200_2011/CUB_200_2011/splits/train/066.Western_Gull/Western_Gull_0065_55728.jpg\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "\n",
    "train_root = \"/Users/saramcghee/.cache/kagglehub/datasets/veeralakrishna/200-bird-species-with-11788-images/versions/1/CUB_200_2011/CUB_200_2011/splits/train\"\n",
    "\n",
    "cls = random.choice(os.listdir(train_root))\n",
    "img = random.choice(os.listdir(os.path.join(train_root, cls)))\n",
    "img_path = os.path.join(train_root, cls, img)\n",
    "\n",
    "print(\"Using image:\", img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e3aa75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multimodal Bird ID (learning mode) ===\n",
      "\n",
      "IMAGE top predictions:\n",
      "  ‚Ä¢ Ring billed Gull                     0.160\n",
      "  ‚Ä¢ Anna Hummingbird                     0.152\n",
      "  ‚Ä¢ Black Tern                           0.139\n",
      "  ‚Ä¢ Rufous Hummingbird                   0.087\n",
      "  ‚Ä¢ Northern Flicker                     0.069\n",
      "\n",
      "AUDIO top predictions:\n",
      "  ‚Ä¢ trochilus                            0.985\n",
      "  ‚Ä¢ argentatus                           0.002\n",
      "  ‚Ä¢ europaea                             0.001\n",
      "  ‚Ä¢ arvensis                             0.001\n",
      "  ‚Ä¢ philomelos                           0.001\n",
      "\n",
      "Agreement check:\n",
      "  üü° Weak agreement: 'Hummingbird' appears in IMAGE top-5\n",
      "\n",
      "Recommendation:\n",
      "  üü° Leaning: Ring billed Gull (audio agrees in top-5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_topk': [('064.Ring_billed_Gull', 0.15985079109668732),\n",
       "  ('067.Anna_Hummingbird', 0.15161050856113434),\n",
       "  ('142.Black_Tern', 0.13938046991825104),\n",
       "  ('069.Rufous_Hummingbird', 0.08712928742170334),\n",
       "  ('036.Northern_Flicker', 0.068853460252285)],\n",
       " 'audio_topk': [('trochilus', 0.9850702318825041),\n",
       "  ('argentatus', 0.002067355445219387),\n",
       "  ('europaea', 0.0014971913708846768),\n",
       "  ('arvensis', 0.0014679615772921779),\n",
       "  ('philomelos', 0.001460973796353702)],\n",
       " 'agreement': 'weak'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "audio_path = \"/Users/saramcghee/.cache/kagglehub/datasets/fleanend/birds-songs-numeric-dataset/versions/3\"\n",
    "audio_test_df = pd.read_csv(os.path.join(audio_path, \"test.csv\"))\n",
    "\n",
    "row = audio_test_df.sample(1, random_state=2)\n",
    "X_audio_row_df = row.drop(columns=[\"id\", \"genus\", \"species\"])\n",
    "\n",
    "multimodal_assistant(img_path, X_audio_row_df, k=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
